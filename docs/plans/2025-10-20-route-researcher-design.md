# Route Researcher Skill - Design Document

**Date:** 2025-10-20
**Status:** Approved for Implementation

## Overview

A Claude Code skill for researching Pacific Northwest mountain peaks and generating comprehensive route beta reports. The skill orchestrates Python scripts to gather data from multiple sources and synthesizes information into structured Markdown documents.

## Goals

- Research mountain peaks in the Pacific Northwest region
- Support various expedition types (glacier climbing, rock climbing, scrambling, hiking)
- Generate comprehensive route beta reports with current conditions
- Provide statistical analysis of gear usage from historical trip reports
- Output structured Markdown documents for reference

## Architecture

### Repository Structure

```
claude-skills/
├── skills/
│   └── route-researcher/
│       ├── SKILL.md                    # Main skill prompt
│       └── tools/
│           ├── peakbagger.py           # CLI for PeakBagger scraping
│           ├── fetch_weather.py        # Mountain weather forecasts
│           ├── fetch_avalanche.py      # NWAC avalanche forecasts
│           ├── calculate_daylight.py   # Sunrise/sunset calculations
│           ├── pyproject.toml          # uv project configuration
│           └── .python-version         # Python version specification
└── route-beta/                         # Generated reports directory
```

### Skill Workflow

1. **User invokes skill** with peak name (e.g., "Research Mt Baker")
2. **Peak validation:**
   - Search PeakBagger for matching peaks
   - If multiple matches: present options to user with links
   - If single match: confirm with user before proceeding
   - If no matches: ask user to verify peak name
3. **Data gathering** (orchestrated via Bash tool):
   - Run `peakbagger.py` for peak info, trip reports, gear statistics
   - Run `fetch_weather.py` for weather forecasts
   - Run `fetch_avalanche.py` for avalanche conditions (if applicable)
   - Run `calculate_daylight.py` for sunrise/sunset times
   - Use WebFetch/WebSearch for qualitative sources (forums, route descriptions)
4. **Data synthesis:**
   - Analyze route type (glacier/rock/scramble/hike) from descriptions
   - Extract difficulty ratings (YDS class, scramble class, etc.)
   - Compile all information into structured Markdown
5. **Report generation:**
   - Save to `route-beta/YYYY-MM-DD-peak-name.md`
   - Include safety disclaimer at top
   - Explicitly document any information gaps
6. **Confirmation:** Report file path to user

## Data Sources

### Primary Sources (via Python Scripts)

**PeakBagger.com** (`peakbagger.py`)
- Peak information (elevation, prominence, coordinates)
- Trip reports with dates and conditions
- Gear usage statistics (adaptive timeframe based on available data)
- GPS tracks (links to reports with GPX files)
- Sample metadata (number of reports, date range, confidence level)

**Mountain Weather Services** (`fetch_weather.py`)
- Mountain-Forecast.com
- NOAA mountain weather forecasts
- Multi-day forecasts
- Seasonal weather patterns

**Northwest Avalanche Center** (`fetch_avalanche.py`)
- Current avalanche danger ratings by elevation
- Avalanche problem types
- Travel recommendations
- Regional forecasts

**Daylight Calculations** (`calculate_daylight.py`)
- Sunrise/sunset times for current date
- Available daylight hours
- Based on peak coordinates

### Secondary Sources (via WebFetch/WebSearch)

- **Summit Post** - Route descriptions, beta, conditions
- **Mountain Project** - Climbing route information
- **CascadeClimbers.com** - Recent trip reports, forum discussions
- **Mountaineers.org** - Historical reports, route guides
- **PeakBagger.com** (qualitative) - Route descriptions, conditions notes
- **Forest Service websites** - Permits, road access, seasonal closures

## Technology Stack

### Python Environment
- **uv** - Modern Python environment management
- **Python 3.11+** - Specified in `.python-version`

### Core Dependencies

```toml
[project]
name = "route-researcher-tools"
dependencies = [
    "click>=8.1.0",           # CLI framework
    "httpx>=0.27.0",          # Modern HTTP client
    "beautifulsoup4>=4.12.0", # HTML parsing
    "lxml>=5.0.0",            # Fast XML/HTML parser
    "pydantic>=2.0.0",        # Data validation
    "rich>=13.0.0",           # Terminal output formatting
]
```

### Script Execution
All scripts executed via: `uv run python <script>.py <args>`

## Output Document Structure

Generated reports saved as: `route-beta/YYYY-MM-DD-peak-name.md`

### Document Template

```markdown
# [Peak Name] - Route Beta Research

> **⚠️ AI-Generated Research Document**
>
> This document was generated by an AI assistant and should be used as a **starting point only**.
>
> **YOU MUST:**
> - Verify all critical information from primary sources
> - Use your own judgment and experience to assess conditions and risk
> - Cross-reference with current trip reports and local conditions
> - Understand that conditions change rapidly in the mountains
>
> **This is NOT a substitute for:**
> - Proper training and experience
> - Current weather and avalanche forecasts
> - Your own research and route planning
> - Sound mountaineering judgment
>
> The mountains are inherently dangerous. You are responsible for your own safety.

**Generated:** YYYY-MM-DD
**Route Type:** [glacier/rock/scramble/hike - determined by skill]
**Difficulty:** [e.g., "Class 3 scramble" or "5.7 rock" or "Moderate glacier"]

## Summit Information
- Elevation: [from PeakBagger]
- Prominence: [from PeakBagger]
- Location: [coordinates, region]
- PeakBagger: [link]

## Route Description
- **Trailhead:** [name and Google Maps link for driving directions]
- **Drive Time:** [estimated from major city, e.g., "~3 hours from Seattle"]
- **Elevation Gain:** [typical gain, e.g., "7,000 ft"]
- **Distance:** [round trip]
- **Estimated Time:** [typical duration]

### Route Details
[Synthesized from Summit Post, Mountain Project, Mountaineers.org]
- Standard route(s)
- Approach details
- Key waypoints

### Crux
[One paragraph describing the hardest/most technical section]
- What makes it challenging
- Where it's located on route
- Skills/gear required for this section

### Hazards & Safety
[Synthesized from multiple sources]
- Known hazards (crevasses, rockfall, exposure)
- Bailout options
- Emergency contacts

### GPS Tracks
[Link to PeakBagger trip reports with GPX tracks]
- Direct link to filter: "View all reports with GPS tracks"

## Current Conditions & Weather

### Daylight
- **Sunrise/Sunset:** [times for current date]
- **Available Daylight:** [hours of daylight]
- **Considerations:** [e.g., "Plan for alpine start if attempting summit"]

### Weather Forecast
[From Mountain-Forecast.com, NOAA]
- Multi-day forecast
- Seasonal patterns for this time of year

### Avalanche Forecast
[From NWAC - if applicable for route]
- Current danger rating by elevation
- Problem types
- Travel advice

## Gear Statistics & Recommendations
[From PeakBagger analysis]
- Sample size: "Based on X reports over Y years (YYYY-YYYY)"
- Gear usage percentages (ice axe, crampons, rope, etc.)
- Seasonal trends if available
- Confidence level: High/Medium/Low

## Recent Trip Reports
[Links from CascadeClimbers, PeakBagger, Summit Post]
- Most recent 5-10 reports with dates and links
- Key takeaways from recent conditions

## Access & Permits
[From Forest Service, park websites]
- Trailhead access and road conditions
- Required permits
- Seasonal closures

## Information Gaps
[Explicit callouts where data was insufficient]
- Example: "Limited trip reports available for winter season"
- Example: "No recent avalanche data found for this region"
```

## Python Scripts Design

### peakbagger.py

**CLI tool using Click framework**

**Commands:**
```bash
# Search for peaks by name
uv run python peakbagger.py search "Mt Baker"

# Get detailed peak information
uv run python peakbagger.py peak-info "Mt Baker" --format json

# Get gear statistics from trip reports
uv run python peakbagger.py stats "Mt Baker" --format json
```

**Data Extraction:**
- Peak information (elevation, prominence, coordinates, PeakBagger URL)
- All available trip reports for the peak
- Gear usage analysis across reports (adaptive timeframe)
- Statistical metadata (sample size, date range, confidence level)
- Links to reports with GPS tracks

**Output Format:**
JSON to stdout for easy parsing by skill

**Adaptive Analysis:**
- Pull ALL available trip reports for the peak
- Calculate gear statistics across entire dataset
- Include metadata: "Analyzed 47 reports spanning 8 years (2017-2025)"
- Provide confidence indicators based on sample size:
  - High: 50+ reports
  - Medium: 15-49 reports
  - Low: <15 reports

### fetch_weather.py

**Weather forecast retrieval**

**Usage:**
```bash
uv run python fetch_weather.py --peak-name "Mt Baker" --coordinates "48.7767,-121.8144"
```

**Sources:**
- Mountain-Forecast.com (primary)
- NOAA mountain weather (secondary)

**Output:**
- Multi-day forecast (temperature, precipitation, wind)
- Seasonal patterns for current time of year
- JSON format to stdout

### fetch_avalanche.py

**NWAC avalanche forecast retrieval**

**Usage:**
```bash
uv run python fetch_avalanche.py --region "North Cascades" --coordinates "48.7767,-121.8144"
```

**Output:**
- Current avalanche danger ratings by elevation band
- Avalanche problem types
- Travel recommendations
- JSON format to stdout

### calculate_daylight.py

**Sunrise/sunset calculations**

**Usage:**
```bash
uv run python calculate_daylight.py --date "2025-10-20" --coordinates "48.7767,-121.8144"
```

**Output:**
- Sunrise time
- Sunset time
- Total daylight hours
- JSON format to stdout

## Error Handling

### Script Failures
- If a script fails, note in "Information Gaps" section
- Continue with other data sources
- Don't block entire research on single script failure

### Missing Data
- Explicitly document what wasn't found and why
- Examples:
  - "No GPS tracks available for this peak"
  - "Limited trip reports in winter season (only 3 reports found)"
  - "Weather forecast unavailable - check Mountain-Forecast.com directly"

### Network Issues
- Retry once on network failures
- Document gap if retry fails
- Provide direct links for manual checking

### Invalid Peak Name
- Ask user to clarify before starting full research
- Provide PeakBagger search suggestions if available

### Timeouts
- Each Python script: 30 second timeout
- Each WebFetch operation: standard timeout
- Total skill execution: ~3-5 minutes typical

## Skill Invocation Examples

**Simple invocation:**
```
User: "Research Mt Baker"
```

**With context:**
```
User: "I'm planning a climb of Sahale Peak next month. Can you research the route for me?"
```

**The skill should:**
1. Extract peak name ("Mt Baker" or "Sahale Peak")
2. Search PeakBagger and validate with user
3. Gather all data
4. Generate comprehensive report
5. Save to `route-beta/YYYY-MM-DD-peak-name.md`

## Data Quality Principles

1. **Transparency:** Always show sample sizes and data sources
2. **Honesty:** Explicitly document information gaps
3. **Safety:** Prominent disclaimer that this is AI-generated research
4. **Verification:** Encourage user to cross-reference with primary sources
5. **Recency:** Prioritize recent trip reports and current conditions
6. **Comprehensiveness:** Cover all aspects (route, weather, gear, safety, access)

## Implementation Phases

### Phase 1: Core Infrastructure
- Set up `skills/route-researcher/` directory structure
- Create `pyproject.toml` with dependencies
- Implement basic SKILL.md with invocation logic

### Phase 2: PeakBagger Script
- Implement `peakbagger.py` with Click CLI
- Build search functionality
- Build peak info extraction
- Build trip report scraping
- Build gear statistics analysis

### Phase 3: Weather & Conditions Scripts
- Implement `fetch_weather.py`
- Implement `fetch_avalanche.py`
- Implement `calculate_daylight.py`

### Phase 4: Skill Integration
- Complete SKILL.md with full orchestration logic
- Implement validation workflow
- Implement data synthesis
- Implement Markdown generation

### Phase 5: Testing & Refinement
- Test with various PNW peaks (Baker, Rainier, Sahale, etc.)
- Refine error handling
- Validate output format
- Test edge cases (obscure peaks, limited data)

## Success Criteria

A successful implementation will:
1. ✅ Accept peak name and validate against PeakBagger
2. ✅ Gather data from all specified sources
3. ✅ Generate comprehensive, well-structured Markdown reports
4. ✅ Handle missing data gracefully with explicit gaps
5. ✅ Provide statistical gear analysis with confidence indicators
6. ✅ Include current weather and avalanche conditions
7. ✅ Calculate and display daylight information
8. ✅ Save reports to standardized location
9. ✅ Execute within reasonable time (<5 minutes)
10. ✅ Include prominent safety disclaimer

## Future Enhancements (Out of Scope)

- Multi-peak comparison reports
- Seasonal analysis (best months to climb)
- Historical weather patterns
- Crowd-sourced route conditions database
- Integration with personal climbing logs
- Mobile-friendly output format
- Automated report updates based on new trip reports
